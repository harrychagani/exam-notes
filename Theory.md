•  We say a model is able to generalize if
: it predicts well on new, unseen data
•  The test data set is used to:
: estimate how well a model will generalize to unseen, real-world data
•  What does the following code calculate: np.sum((y - y_hat)**2) / n
: mse
•  If you have a Pandas dataframe df and would like to create the feature array to train a machine learning algorithm, you would use:
: df.drop('target', axis=1)
•  In kNN regression, we look at the k neighbours and:
: average the k target values to predict the value
•  What values can R² take on?
: -inf to 1
•  We set the random_state in train_test_split() in order to:
: ensure we always get the same data splits
•  Feature importances measure the drop in the model's:
: validation set accuracy when each feature is removed/randomized
•  The training data set is used to:
: used to learn the values of the network parameters that minimize the error
•  Memorization of the training data will:
: work well for the training data but not be able to make predictions for any other data
•  For a machine learning problem, there are two things we need to verify:
: that the model fits the training data well and that the model generalizes
•  If we would like to find out how often our classification model predicts false positives and false negatives, we could:
: compute the confusion matrix
•  Using all or some of the test data to train the model will:
: will overestimate how well your model will predict when using new, unseen data
•  The central problem of machine learning is to build a system that:
: is accurate without being overly-specific to the training data
•  The objective of a machine learning classifier is to:
: detect the class of a newly given sample
•  The validation data set is used to:
: used to choose between different values of hyperparameters for a network

